{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2fe8b52f-649e-447d-bfd3-857fee2eb4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import netCDF4\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f14a75-7b72-49a5-b9d1-2af6b86923f7",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccc0b7-8bed-451c-b41b-6eae75271828",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min = \"20240321\"\n",
    "date_max = \"20250313\"\n",
    "#\n",
    "paths = {}\n",
    "paths[\"Barents\"] = \"/lustre/storeB/project/copernicus/cosi/PCAPS/Barents_AICE_grid/\"\n",
    "paths[\"AICE\"] = \"/lustre/storeB/project/fou/hi/oper/aice/archive/\"\n",
    "paths[\"Anomaly_persistence\"] = \"/lustre/storeB/project/copernicus/cosi/PCAPS/AMSR2_Anomaly_persistence/\"\n",
    "paths[\"ice_charts\"] = \"/lustre/storeB/project/copernicus/cosi/WP3/Operational/Ice_charts/\"\n",
    "paths[\"AMSR2\"] = \"/lustre/storeB/project/copernicus/cosi/WP3/Operational/AMSR2_obs/\"\n",
    "paths[\"output\"] = \"/lustre/storeB/users/cyrilp/AICE/Stats/Barents_AICE_domain/\"\n",
    "#\n",
    "if os.path.exists(paths[\"output\"]) == False:\n",
    "    os.system(\"mkdir -p \" + paths[\"output\"])\n",
    "#\n",
    "threshold_ice_edge = 10\n",
    "lead_times = np.arange(10)\n",
    "spatial_resolution = 5000\n",
    "N_Barents_members = 6\n",
    "#\n",
    "list_forecasts = [\"Barents\", \"Barents_bias_corrected\", \"AICE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b2ee15-5669-4cb5-a037-1767a5c6fbaf",
   "metadata": {},
   "source": [
    "# List dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84900b1c-0443-4325-8670-d6c82e352979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list_dates(date_min, date_max):\n",
    "    current_date = datetime.datetime.strptime(date_min, \"%Y%m%d\")\n",
    "    end_date = datetime.datetime.strptime(date_max, \"%Y%m%d\")\n",
    "    list_dates = []\n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime(\"%Y%m%d\")\n",
    "        list_dates.append(date_str)\n",
    "        current_date = current_date + datetime.timedelta(days = 1)\n",
    "    return(list_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2731bf5-5363-4056-ae86-a444f9d65564",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a25c11c4-97b9-4f3c-a404-371b04ea1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(list_datasets, date_task, paths, N_Barents_members = N_Barents_members):\n",
    "    Datasets = {}\n",
    "    for ds in list_datasets:\n",
    "        if ds == \"Barents_bias_corrected\":\n",
    "            date_pers = (datetime.datetime.strptime(date_task, \"%Y%m%d\") - datetime.timedelta(days = 1)).strftime(\"%Y%m%d\")\n",
    "            filename_AMSR2 = paths[\"AMSR2\"] + date_pers[0:4] + \"/\" + date_pers[4:6] + \"/\" + \"AMSR2_SIC_AICE_grid_\" + date_pers + \"T000000Z.nc\"\n",
    "            filename_Barents = paths[\"Barents\"] + date_task[0:4] + \"/\" + date_task[4:6] + \"/\" + \"Barents_on_AICE_grid_\" + date_task + \".nc\"\n",
    "            if (os.path.isfile(filename_AMSR2) == True) and (os.path.isfile(filename_Barents) == True):\n",
    "                \n",
    "                with netCDF4.Dataset(filename_AMSR2, \"r\") as nc:\n",
    "                    AMSR2_SIC_persistence = nc.variables[\"SIC\"][0,:,:] \n",
    "\n",
    "                with netCDF4.Dataset(filename_Barents, \"r\") as nc:\n",
    "                    Barents_SIC = nc.variables[\"ice_concentration\"][:] * 100\n",
    "                    Barents_bias_corrected = np.full(np.shape(Barents_SIC), np.nan)\n",
    "                    for me in range(0, N_Barents_members):\n",
    "                        Barents_SIC_t0 = nc.variables[\"ice_concentration_first_hour\"][me,0,:,:] * 100\n",
    "                        ini_bias = Barents_SIC_t0 - AMSR2_SIC_persistence\n",
    "                        Barents_bias_corrected[me,:,:,:] = Barents_SIC[me,:,:,:] - ini_bias\n",
    "                    Barents_bias_corrected[Barents_bias_corrected < 0] = 0\n",
    "                    Barents_bias_corrected[Barents_bias_corrected > 100] = 100\n",
    "                    Datasets[ds] = {}\n",
    "                    Datasets[ds][\"SIC\"] = np.copy(Barents_bias_corrected)       \n",
    "        else:\n",
    "            if ds == \"Barents\":\n",
    "                filename = paths[ds] + date_task[0:4] + \"/\" + date_task[4:6] + \"/\" + \"Barents_on_AICE_grid_\" + date_task + \".nc\"\n",
    "            elif ds == \"AICE\":\n",
    "                filename = paths[ds] + \"AICE_forecasts_\" + date_task + \"T000000Z.nc\"\n",
    "            elif ds == \"Anomaly_persistence\":\n",
    "                filename = paths[ds] + date_task[0:4] + \"/\" + date_task[4:6] + \"/\" + \"Anomaly_persistence_SIC_\" + date_task + \".nc\"\n",
    "            elif ds == \"ice_charts\":\n",
    "                filename = paths[ds] + date_task[0:4] + \"/\" + date_task[4:6] + \"/\" + \"Ice_charts_AICE_grid_\" + date_task + \".nc\"\n",
    "            elif ds == \"AMSR2\":\n",
    "                filename = paths[ds] + date_task[0:4] + \"/\" + date_task[4:6] + \"/\" + \"AMSR2_SIC_AICE_grid_\" + date_task + \"T000000Z.nc\"\n",
    "            #\n",
    "            if os.path.isfile(filename) == True:\n",
    "                with netCDF4.Dataset(filename, \"r\") as nc:\n",
    "                    Datasets[ds] = {}\n",
    "                    for var in nc.variables:\n",
    "                        if ds == \"Barents\" and var == \"ice_concentration\":\n",
    "                            Datasets[ds][\"SIC\"] = nc.variables[var][:] * 100\n",
    "                        else:\n",
    "                            Datasets[ds][var] = nc.variables[var][:]          \n",
    "    return(Datasets)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0204af4-a32b-4a51-b545-fb56402c0b19",
   "metadata": {},
   "source": [
    "# Land sea mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42c5d240-012a-41b1-81a6-a963b14109db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_common_land_sea_mask(Forecasts, Observations):\n",
    "    # 1 ocean, 0 land\n",
    "    LSM_Barents = Forecasts[\"Barents\"][\"sea_mask\"]\n",
    "    #\n",
    "    LSM_AICE = np.ones(np.shape(Forecasts[\"AICE\"][\"SIC\"][0,:,:]))\n",
    "    LSM_AICE[np.isnan(Forecasts[\"AICE\"][\"SIC\"][0,:,:]) == True] = 0\n",
    "    #\n",
    "    LSM_ice_charts = np.ones(np.shape(Observations[\"ice_charts\"][\"SIC\"][0,:,:]))\n",
    "    LSM_ice_charts[np.isnan(Observations[\"ice_charts\"][\"SIC\"][0,:,:]) == True] = 0\n",
    "    #\n",
    "    LSM = np.zeros(np.shape(LSM_AICE))\n",
    "    LSM[np.logical_and(LSM_ice_charts == 1, np.logical_and(LSM_Barents == 1, LSM_AICE == 1))] = 1\n",
    "    #\n",
    "    return(LSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2558edb0-7b17-474c-a58c-7366ba6d20b6",
   "metadata": {},
   "source": [
    "# Calculate ice edge length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47bb2305-70d6-46d8-a2b4-f0d071eea485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class calculate_ice_edge_length():\n",
    "    def __init__(self, SIC, LSM, threshold_ice_edge, spatial_resolution):\n",
    "        self.SIC = np.squeeze(SIC)\n",
    "        self.LSM = np.squeeze(LSM)\n",
    "        self.threshold_ice_edge = threshold_ice_edge\n",
    "        self.spatial_resolution = spatial_resolution\n",
    "        SIE = np.zeros(np.shape(self.SIC))\n",
    "        SIE[self.SIC >= self.threshold_ice_edge] = 1\n",
    "        self.SIE = SIE\n",
    "    #\n",
    "    def ice_edge_position(self):\n",
    "        # Shift the arrays to get the neighboring values\n",
    "        SIE_up = np.roll(self.SIE, -1, axis = 0)\n",
    "        SIE_down = np.roll(self.SIE, 1, axis = 0)\n",
    "        SIE_left = np.roll(self.SIE, -1, axis = 1)\n",
    "        SIE_right = np.roll(self.SIE, 1, axis = 1)\n",
    "        #\n",
    "        LSM_up = np.roll(self.LSM, -1, axis = 0)\n",
    "        LSM_down = np.roll(self.LSM, 1, axis = 0)\n",
    "        LSM_left = np.roll(self.LSM, -1, axis = 1)\n",
    "        LSM_right = np.roll(self.LSM, 1, axis = 1)\n",
    "        #\n",
    "        # Mask the borders \n",
    "        SIE_up[-1, :] = np.nan\n",
    "        SIE_down[0, :] = np.nan\n",
    "        SIE_left[:, -1] = np.nan\n",
    "        SIE_right[:, 0] = np.nan\n",
    "        #\n",
    "        LSM_up[-1, :] = np.nan\n",
    "        LSM_down[0, :] = np.nan\n",
    "        LSM_left[:, -1] = np.nan\n",
    "        LSM_right[:, 0] = np.nan\n",
    "        #\n",
    "        neighbors_SIE = np.stack([SIE_up, SIE_down, SIE_left, SIE_right], axis = 0)\n",
    "        neighbors_LSM = np.stack([LSM_up, LSM_down, LSM_left, LSM_right], axis = 0)\n",
    "        #\n",
    "        open_ocean_neighbors = np.logical_and(neighbors_SIE == 0, neighbors_LSM == 1)\n",
    "        nb_neighbors_open_ocean = np.nansum(open_ocean_neighbors, axis = 0)\n",
    "        #\n",
    "        ice_edge = np.zeros(np.shape(self.SIE))\n",
    "        ice_edge[np.logical_and(nb_neighbors_open_ocean >= 1, self.SIE == 1)] = 1\n",
    "        return(ice_edge)\n",
    "    #\n",
    "    def length_sea_ice_edge(self, ice_edge):\n",
    "        # Convolution kernel to count the neighbors\n",
    "        kernel = np.array([[0, 1, 0], \n",
    "                           [1, 0, 1], \n",
    "                           [0, 1, 0]])\n",
    "        # Count neighbors using convolution\n",
    "        neighbor_count = scipy.ndimage.convolve(ice_edge, kernel, mode = \"constant\", cval = 0)\n",
    "        length_sie = np.zeros(np.shape(ice_edge))\n",
    "        length_sie[np.logical_and(neighbor_count == 0, ice_edge == 1)] = np.sqrt(2) * self.spatial_resolution\n",
    "        length_sie[np.logical_and(neighbor_count == 1, ice_edge == 1)] = 0.5 * (self.spatial_resolution + np.sqrt(2) * self.spatial_resolution)\n",
    "        length_sie[np.logical_and(neighbor_count >= 2, ice_edge == 1)] = self.spatial_resolution\n",
    "        sie_length = np.sum(length_sie)\n",
    "        return(sie_length)\n",
    "    #\n",
    "    def __call__(self):\n",
    "        ice_edge = self.ice_edge_position()\n",
    "        ice_edge_length = self.length_sea_ice_edge(ice_edge)\n",
    "        return(ice_edge_length, ice_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265de0d-447f-4e8b-9c1c-508404e70593",
   "metadata": {},
   "source": [
    "# Verification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "06eace61-0929-48fc-b15d-ed8b962ee202",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ice_edge_verification_scores():\n",
    "    def __init__(self, SIC_obs, SIC_forecast, ice_edge_length, threshold_ice_edge, spatial_resolution, LSM, probabilistic = False):\n",
    "        self.SIC_obs = np.squeeze(SIC_obs)  # If deterministic \"SIC_obs and SIC_forecasts\" must be 2D arrays (y, x). If probabilistic, they must be 3D arrays (member, y x)\n",
    "        self.SIC_forecast = np.squeeze(SIC_forecast)\n",
    "        self.ice_edge_length = ice_edge_length\n",
    "        self.threshold_ice_edge = threshold_ice_edge\n",
    "        self.spatial_resolution = spatial_resolution\n",
    "        self.LSM = np.squeeze(LSM)\n",
    "        self.probabilistic = probabilistic\n",
    "    #\n",
    "    def sea_ice_extent(self, SIC):\n",
    "        SIE = np.zeros(np.shape(SIC))\n",
    "        SIE[SIC >= self.threshold_ice_edge] = 1\n",
    "        return(SIE)\n",
    "    #\n",
    "    def sea_ice_probability(self, SIC):\n",
    "        SIE = np.zeros(np.shape(SIC))\n",
    "        SIE[SIC >= self.threshold_ice_edge] = 1\n",
    "        SIP = np.sum(SIE, axis = 0) / np.shape(SIE)[0]\n",
    "        return(SIP)\n",
    "    #\n",
    "    def Root_Mean_Square_Error(self):\n",
    "        # SIC_forec and SIC_obs must be 2D arrays (y, x)\n",
    "        SIC_forec = np.ndarray.flatten(self.SIC_forecast[self.LSM == 1])\n",
    "        SIC_ob = np.ndarray.flatten(self.SIC_obs[self.LSM == 1])\n",
    "        MSE = np.sum((SIC_forec - SIC_ob) ** 2) / len(SIC_ob)\n",
    "        RMSE = np.sqrt(MSE)\n",
    "        return(RMSE)\n",
    "    #\n",
    "    def IIEE(self):\n",
    "        SIE_obs = self.sea_ice_extent(self.SIC_obs)\n",
    "        SIE_forecast = self.sea_ice_extent(self.SIC_forecast)\n",
    "        SIE_obs[self.LSM < 1] = 0\n",
    "        SIE_forecast[self.LSM < 1] = 0\n",
    "        Flag_SIE = np.full(np.shape(SIE_obs), np.nan)\n",
    "        Flag_SIE[SIE_forecast == SIE_obs] = 0\n",
    "        Flag_SIE[SIE_forecast < SIE_obs] = -1\n",
    "        Flag_SIE[SIE_forecast > SIE_obs] = 1\n",
    "        Underestimation = np.sum(Flag_SIE == -1) * self.spatial_resolution ** 2\n",
    "        Overestimation = np.sum(Flag_SIE == 1) * self.spatial_resolution ** 2\n",
    "        IIEE_metric = Underestimation + Overestimation\n",
    "        return(IIEE_metric, Underestimation, Overestimation)\n",
    "    #\n",
    "    def SPS(self):\n",
    "        SIP_obs = self.sea_ice_extent(self.SIC_obs)\n",
    "        SIP_forecast = self.sea_ice_probability(self.SIC_forecast)\n",
    "        SIP_obs[self.LSM < 1] = 0\n",
    "        SIP_forecast[self.LSM < 1] = 0\n",
    "        SPS_metric = np.nansum((self.spatial_resolution ** 2) * (SIP_forecast - SIP_obs)**2)\n",
    "        return(SPS_metric)\n",
    "    #\n",
    "    def __call__(self):\n",
    "        if self.probabilistic == False:\n",
    "            IIEE_distance = self.IIEE()[0] / self.ice_edge_length\n",
    "            RMSE = self.Root_Mean_Square_Error()\n",
    "            if np.ma.isMaskedArray(RMSE) == True:\n",
    "                RMSE = np.nan\n",
    "            return(IIEE_distance, RMSE)\n",
    "        #\n",
    "        elif self.probabilistic == True:\n",
    "            N_members = np.shape(SIC_forecast)[0]\n",
    "            SPS_distance = self.SPS() / self.ice_edge_length\n",
    "            return(SPS_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aff6978-6e29-4a46-aa8e-6e2417288b4b",
   "metadata": {},
   "source": [
    "# Write_scores function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "026fc6aa-e5f0-4e1f-9331-efd0d8536872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scores(Metrics, ds_obs, lt, date_min, date_max, paths = paths):\n",
    "    header = \"\"\n",
    "    scores = \"\"\n",
    "    for vi, var in enumerate(sorted(Metrics.keys(), reverse = True)):\n",
    "        header = header + \"\\t\" + var   \n",
    "        scores = scores + \"\\t\" + str(Metrics[var]) \n",
    "    #\n",
    "    output_file = paths[\"output\"] + \"Scores_ice_edge_reference_\" + ds_obs + \"_lead_time_\" + str(lt) + \".txt\"\n",
    "    if start_date == date_min:\n",
    "        if os.path.isfile(output_file) == True:\n",
    "            os.system(\"rm \" + output_file)\n",
    "    #\n",
    "    if os.path.isfile(output_file) == False:\n",
    "        output = open(output_file, 'a')\n",
    "        output.write(header + \"\\n\")\n",
    "        output.close()\n",
    "    #\n",
    "    output = open(output_file, 'a')\n",
    "    output.write(scores + \"\\n\")\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ed242-1b2e-46c0-841a-e999a1f8057b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "943f634e-a70c-44f4-9ec8-80f37684a604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240321\n",
      "20240322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3005863/4265662133.py:47: RuntimeWarning: Mean of empty slice\n",
      "  SIC_ensemble_mean = np.nanmean(Forecasts[ds_forec][\"SIC\"][:,lt,:,:], axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240323\n",
      "20240324\n",
      "20240325\n",
      "20240326\n",
      "20240327\n",
      "20240328\n",
      "20240329\n",
      "20240330\n",
      "20240331\n",
      "20240401\n"
     ]
    }
   ],
   "source": [
    "list_dates = make_list_dates(date_min, date_max)\n",
    "for sdi, start_date in enumerate(list_dates):\n",
    "    print(start_date)\n",
    "    persistence_date = (datetime.datetime.strptime(start_date, \"%Y%m%d\") - datetime.timedelta(days = 1)).strftime(\"%Y%m%d\")\n",
    "    Forecasts = load_datasets(list_forecasts, start_date, paths)\n",
    "    if all(key in Forecasts for key in list_forecasts) == True:\n",
    "        Obs_persistence = load_datasets([\"ice_charts\", \"AMSR2\"], persistence_date, paths)\n",
    "        Anomaly_persistence = load_datasets([\"Anomaly_persistence\"], persistence_date, paths)\n",
    "        #\n",
    "        if \"LSM\" not in locals():\n",
    "            LSM = make_common_land_sea_mask(Forecasts, Obs_persistence)\n",
    "        #\n",
    "        for lt in lead_times:\n",
    "            forec_date = (datetime.datetime.strptime(start_date, \"%Y%m%d\") + datetime.timedelta(days = int(lt))).strftime(\"%Y%m%d\")\n",
    "            Obs_target = load_datasets([\"AMSR2\", \"ice_charts\"], forec_date, paths)\n",
    "            #\n",
    "            for ds_obs in Obs_target:\n",
    "                Metrics = {}\n",
    "                Metrics[\"start_date\"] = start_date\n",
    "                Metrics[\"forecast_date\"] = forec_date\n",
    "                #\n",
    "                SIC_obs = np.squeeze(Obs_target[ds_obs][\"SIC\"])\n",
    "                SIC_obs[LSM == 0] = 0\n",
    "                ice_edge_length = calculate_ice_edge_length(SIC_obs, LSM, threshold_ice_edge, spatial_resolution)()[0]\n",
    "                Metrics[\"Ice_edge_length\"] = ice_edge_length\n",
    "                #\n",
    "                if \"Anomaly_persistence\" in Anomaly_persistence:\n",
    "                    SIC_anomaly_pers = Anomaly_persistence[\"Anomaly_persistence\"][\"SIC\"][lt + 1,:,:]   \n",
    "                    SIC_anomaly_pers[LSM == 0] = 0\n",
    "                    Metrics[\"IIEE_distance_Anomaly_persistence\"], Metrics[\"RMSE_Anomaly_persistence\"] = ice_edge_verification_scores(SIC_obs, SIC_anomaly_pers, ice_edge_length, threshold_ice_edge, spatial_resolution, LSM, probabilistic = False)()\n",
    "                else:\n",
    "                    Metrics[\"IIEE_distance_Anomaly_persistence\"] = np.nan\n",
    "                    Metrics[\"RMSE_Anomaly_persistence\"] = np.nan\n",
    "                #\n",
    "                for ds_pers in Obs_persistence:\n",
    "                    SIC_pers = np.squeeze(Obs_persistence[ds_pers][\"SIC\"])\n",
    "                    SIC_pers[LSM == 0] = 0\n",
    "                    Metrics[\"IIEE_distance_Persistence_\" + ds_pers], Metrics[\"RMSE_Persistence_\" + ds_pers] = ice_edge_verification_scores(SIC_obs, SIC_pers, ice_edge_length, threshold_ice_edge, spatial_resolution, LSM, probabilistic = False)()  \n",
    "                #\n",
    "                for ds_forec in Forecasts:\n",
    "                    if ds_forec == \"AICE\":\n",
    "                        SIC_forecast = Forecasts[ds_forec][\"SIC\"][lt,:,:]\n",
    "                        SIC_forecast[LSM == 0] = 0\n",
    "                        Metrics[\"IIEE_distance_\" + ds_forec], Metrics[\"RMSE_\" + ds_forec] = ice_edge_verification_scores(SIC_obs, SIC_forecast, ice_edge_length, threshold_ice_edge, spatial_resolution, LSM, probabilistic = False)()\n",
    "                    elif (ds_forec == \"Barents\") or (ds_forec == \"Barents_bias_corrected\"):\n",
    "                        if lt < 4:\n",
    "                            SIC_ensemble_mean = np.nanmean(Forecasts[ds_forec][\"SIC\"][:,lt,:,:], axis = 0)\n",
    "                            SIC_ensemble_mean[LSM == 0] = 0\n",
    "                            SIC_forecast = Forecasts[ds_forec][\"SIC\"][:,lt,:,:]\n",
    "                            LSM_extend = np.repeat(np.expand_dims(LSM, axis = 0), N_Barents_members, axis = 0)\n",
    "                            SIC_forecast[LSM_extend == 0] = 0\n",
    "                            Metrics[\"IIEE_distance_ensemble_mean_\" + ds_forec], Metrics[\"RMSE_ensemble_mean_\" + ds_forec] = ice_edge_verification_scores(SIC_obs, SIC_ensemble_mean, ice_edge_length, threshold_ice_edge, spatial_resolution, LSM, probabilistic = False)()\n",
    "                            Metrics[\"SPS_distance_\" + ds_forec] = ice_edge_verification_scores(SIC_obs, SIC_forecast, ice_edge_length, threshold_ice_edge, spatial_resolution, LSM, probabilistic = True)()\n",
    "                            #\n",
    "                            for me in range(0, N_Barents_members):\n",
    "                                member = \"{:02d}\".format(me)\n",
    "                                Metrics[\"IIEE_distance_\" + ds_forec + \"_member_\" + member], Metrics[\"RMSE_\" + ds_forec + \"_member_\" + member] = ice_edge_verification_scores(SIC_obs, SIC_forecast[me,:,:], ice_edge_length, threshold_ice_edge, spatial_resolution, LSM, probabilistic = False)()\n",
    "                #\n",
    "                if \"ice_charts\" not in Obs_persistence:\n",
    "                    Metrics[\"IIEE_distance_Persistence_ice_charts\"] = np.nan\n",
    "                    Metrics[\"RMSE_Persistence_ice_charts\"] = np.nan\n",
    "                if \"AMSR2\" not in Obs_persistence:                \n",
    "                    Metrics[\"IIEE_distance_Persistence_AMSR2\"] = np.nan   \n",
    "                    Metrics[\"RMSE_Persistence_AMSR2\"] = np.nan   \n",
    "                #\n",
    "                for var in Metrics:\n",
    "                    if \"date\" not in var:\n",
    "                        Metrics[var] = np.round(Metrics[var], 3)\n",
    "                #\n",
    "                save_scores(Metrics, ds_obs, lt, date_min, date_max, paths = paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3617a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
